{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "\n",
    "df = pd.read_json(\"scores.jsonl\", lines=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "item = df.iloc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>survey_id</th>\n",
       "      <th>survey_title</th>\n",
       "      <th>section_title</th>\n",
       "      <th>section_text_in_survey</th>\n",
       "      <th>citations</th>\n",
       "      <th>generated_section_text</th>\n",
       "      <th>score</th>\n",
       "      <th>scores</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2011.06801v1</td>\n",
       "      <td>A Comprehensive Survey on Deep Music Generatio...</td>\n",
       "      <td>Datasets::MIDI</td>\n",
       "      <td>As introduced in Section 3, MIDI is a descrip...</td>\n",
       "      <td>{'bibrefs': ['BIBREF199', 'BIBREF315', 'BIBREF...</td>\n",
       "      <td>{'gpt-3.5-turbo': {'text': 'Datasets - MIDI\n",
       "\n",
       "M...</td>\n",
       "      <td>3.95</td>\n",
       "      <td>[4.0, 4.0, 4.0, 3.0, 4.0, 4.0, 4.0, 4.0, 4.0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2309.15402v1</td>\n",
       "      <td>A Survey of Chain of Thought Reasoning: Advanc...</td>\n",
       "      <td>Discussion::Comparison between Verification/Re...</td>\n",
       "      <td>Numerous parallels exist between planning meth...</td>\n",
       "      <td>{'bibrefs': ['BIBREF16', 'BIBREF80', 'BIBREF81...</td>\n",
       "      <td>{'gpt-3.5-turbo': {'text': 'Discussion - Compa...</td>\n",
       "      <td>4.00</td>\n",
       "      <td>[4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2309.15402v1</td>\n",
       "      <td>A Survey of Chain of Thought Reasoning: Advanc...</td>\n",
       "      <td>Methods::XoT Structural Variants::Tree Structure</td>\n",
       "      <td>The original chain structure inherently limits...</td>\n",
       "      <td>{'bibrefs': ['BIBREF16', 'BIBREF80', 'BIBREF14...</td>\n",
       "      <td>{'gpt-3.5-turbo': {'text': 'Methods - XoT Stru...</td>\n",
       "      <td>4.00</td>\n",
       "      <td>[4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2105.03075v5</td>\n",
       "      <td>A Survey of Data Augmentation Approaches for NLP</td>\n",
       "      <td>Applications::Adversarial Examples (AVEs)</td>\n",
       "      <td>Adversarial examples can be generated using in...</td>\n",
       "      <td>{'bibrefs': ['BIBREF92', 'BIBREF90', 'BIBREF89...</td>\n",
       "      <td>{'gpt-3.5-turbo': {'text': 'Applications - Adv...</td>\n",
       "      <td>4.00</td>\n",
       "      <td>[4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2105.03075v5</td>\n",
       "      <td>A Survey of Data Augmentation Approaches for NLP</td>\n",
       "      <td>Applications::Few-Shot Learning</td>\n",
       "      <td>DA methods can ease few-shot learning by addin...</td>\n",
       "      <td>{'bibrefs': ['BIBREF21', 'BIBREF88', 'BIBREF87...</td>\n",
       "      <td>{'gpt-3.5-turbo': {'text': 'Applications - Few...</td>\n",
       "      <td>4.00</td>\n",
       "      <td>[4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      survey_id                                       survey_title  \\\n",
       "0  2011.06801v1  A Comprehensive Survey on Deep Music Generatio...   \n",
       "1  2309.15402v1  A Survey of Chain of Thought Reasoning: Advanc...   \n",
       "2  2309.15402v1  A Survey of Chain of Thought Reasoning: Advanc...   \n",
       "3  2105.03075v5   A Survey of Data Augmentation Approaches for NLP   \n",
       "4  2105.03075v5   A Survey of Data Augmentation Approaches for NLP   \n",
       "\n",
       "                                       section_title  \\\n",
       "0                                     Datasets::MIDI   \n",
       "1  Discussion::Comparison between Verification/Re...   \n",
       "2   Methods::XoT Structural Variants::Tree Structure   \n",
       "3          Applications::Adversarial Examples (AVEs)   \n",
       "4                    Applications::Few-Shot Learning   \n",
       "\n",
       "                              section_text_in_survey  \\\n",
       "0   As introduced in Section 3, MIDI is a descrip...   \n",
       "1  Numerous parallels exist between planning meth...   \n",
       "2  The original chain structure inherently limits...   \n",
       "3  Adversarial examples can be generated using in...   \n",
       "4  DA methods can ease few-shot learning by addin...   \n",
       "\n",
       "                                           citations  \\\n",
       "0  {'bibrefs': ['BIBREF199', 'BIBREF315', 'BIBREF...   \n",
       "1  {'bibrefs': ['BIBREF16', 'BIBREF80', 'BIBREF81...   \n",
       "2  {'bibrefs': ['BIBREF16', 'BIBREF80', 'BIBREF14...   \n",
       "3  {'bibrefs': ['BIBREF92', 'BIBREF90', 'BIBREF89...   \n",
       "4  {'bibrefs': ['BIBREF21', 'BIBREF88', 'BIBREF87...   \n",
       "\n",
       "                              generated_section_text  score  \\\n",
       "0  {'gpt-3.5-turbo': {'text': 'Datasets - MIDI\n",
       "\n",
       "M...   3.95   \n",
       "1  {'gpt-3.5-turbo': {'text': 'Discussion - Compa...   4.00   \n",
       "2  {'gpt-3.5-turbo': {'text': 'Methods - XoT Stru...   4.00   \n",
       "3  {'gpt-3.5-turbo': {'text': 'Applications - Adv...   4.00   \n",
       "4  {'gpt-3.5-turbo': {'text': 'Applications - Few...   4.00   \n",
       "\n",
       "                                              scores  \n",
       "0  [4.0, 4.0, 4.0, 3.0, 4.0, 4.0, 4.0, 4.0, 4.0, ...  \n",
       "1  [4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, ...  \n",
       "2  [4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, ...  \n",
       "3  [4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, ...  \n",
       "4  [4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, ...  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Datasets - MIDI\\n\\nMIDI (Musical Instrument Digital Interface) is a widely used format for representing music in a digital form. MIDI datasets have played a crucial role in advancing deep music generation research. In this section, we discuss several notable MIDI datasets that have been used for deep music generation tasks.\\n\\nThe KernScores dataset [REF0] contains classical music in a Humdrum format and is obtained through an optical music recognition system. It provides a valuable resource for studying classical music composition and analysis. Another dataset, Kunstderfuge [REF0], includes solo piano and non-solo piano works of 598 composers. The piano-midi.de, classical archives, and Kunstderfuge datasets are entered using a MIDI sequencer and are not played by pianists [REF0].\\n\\nThe MAPS dataset [REF0] utilizes MIDI files from Piano-midi.de to render real recordings by playing back the MIDI files on a Yamaha Disklavier. This dataset enables researchers to explore the relationship between MIDI representations and real piano performances. The MAESTRO dataset [REF0] contains over 200 hours of fine alignment MIDI files and audio recordings. It features virtuoso pianists performing on Yamaha Disklaviers with an integrated MIDI capture system. MAESTRO encompasses music works from 62 composers, providing a diverse and high-quality resource for deep music generation research [REF0].\\n\\nMIDI datasets offer various advantages for deep music generation tasks. They provide a structured representation of music, including information about pitch, duration, articulation marking, tempo, and more [REF6]. This rich set of features allows models to capture the nuances of musical expression. Additionally, MIDI datasets enable the exploration of multi-instrumental music generation by assigning notes to different instrument voices [REF3].\\n\\nHowever, MIDI datasets also have limitations. They often lack expressive performance features, such as absolute tempo, velocity, and articulation usage [REF6]. This can limit the ability of models to generate music with realistic and nuanced performances. Furthermore, MIDI datasets may not fully capture the intricacies of human performances, as they are often created through sequencers rather than being played by musicians [REF0].\\n\\nIn summary, MIDI datasets have been instrumental in advancing deep music generation research. They provide structured representations of music and enable the exploration of multi-instrumental music generation. However, they also have limitations in capturing expressive performance features. Future research should focus on addressing these limitations and developing more comprehensive and diverse MIDI datasets for deep music generation tasks.\\n\\n[REF0] Sapp, C. (2005). The KernScores dataset.\\n[REF0] Kunstderfuge. (2002). The Kunstderfuge dataset.\\n[REF0] Emiya, V., et al. (2010). The MAPS dataset.\\n[REF0] Hawthorne, C., et al. (2019). The MAESTRO dataset.\\n[REF3] Davis, B., & Mohammad, S. (Year). Title of the paper.\\n[REF6] Author, A., & Author, B. (Year). Title of the paper.'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "item[\"generated_section_text\"][\"gpt-3.5-turbo\"][\"text\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from argparse import ArgumentParser\n",
    "from dotenv import load_dotenv\n",
    "from openai import OpenAI\n",
    "import json, os\n",
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "from instructor import OpenAISchema\n",
    "from pydantic import BaseModel, Field, conint, field_validator,confloat\n",
    "from typing import List\n",
    "\n",
    "class ChecklistItem(BaseModel):\n",
    "    number: conint(ge=1) = Field(..., description=\"The item number\")\n",
    "    text: str = Field(..., description=\"The text of the checklist item\")\n",
    "\n",
    "class from argparse import ArgumentParser\n",
    "from dotenv import load_dotenv\n",
    "from openai import OpenAI\n",
    "import json, os\n",
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "from instructor import OpenAISchema\n",
    "from pydantic import BaseModel, Field, conint, field_validator,confloat\n",
    "from typing import List\n",
    "\n",
    "class ChecklistItem(BaseModel):\n",
    "    number: conint(ge=1) = Field(..., description=\"The item number\")\n",
    "    text: str = Field(..., description=\"The text of the checklist item\")\n",
    "\n",
    "class Checklist(OpenAISchema):\n",
    "    items: List[ChecklistItem] = Field(..., description=\"The checklist items\")\n",
    "\n",
    "    def to_json(self):\n",
    "        return json.dumps(self.dict(), indent=4)(OpenAISchema):\n",
    "    items: List[ChecklistItem] = Field(..., description=\"The checklist items\")\n",
    "\n",
    "    def to_json(self):\n",
    "        return json.dumps(self.dict(), indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'name': 'Checklist',\n",
       " 'description': 'Correctly extracted `Checklist` with all the required parameters with correct types',\n",
       " 'parameters': {'$defs': {'ChecklistItem': {'properties': {'number': {'description': 'The item number',\n",
       "      'minimum': 1,\n",
       "      'title': 'Number',\n",
       "      'type': 'integer'},\n",
       "     'text': {'description': 'The text of the checklist item',\n",
       "      'title': 'Text',\n",
       "      'type': 'string'}},\n",
       "    'required': ['number', 'text'],\n",
       "    'title': 'ChecklistItem',\n",
       "    'type': 'object'}},\n",
       "  'properties': {'items': {'description': 'The checklist items',\n",
       "    'items': {'$ref': '#/$defs/ChecklistItem'},\n",
       "    'title': 'Items',\n",
       "    'type': 'array'}},\n",
       "  'required': ['items'],\n",
       "  'type': 'object'}}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Checklist.openai_schema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_json(\"v3_evaluated_gpt-4-1106-preview_merged_scores.jsonl\", lines=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Axes: >"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "df[\"score_checkeval\"].hist(bins=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    79.000000\n",
       "mean      0.208461\n",
       "std       0.180579\n",
       "min       0.000000\n",
       "25%       0.083333\n",
       "50%       0.166667\n",
       "75%       0.292857\n",
       "max       0.700000\n",
       "Name: score_checkeval, dtype: float64"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"score_checkeval\"].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "item = df[df[\"score_checkeval\"] == 0.0].iloc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "candidate = item[\"generated_section_text\"][\"gpt-3.5-turbo\"][\"text\"]\n",
    "references = item[\"generated_section_text\"][\"gpt-3.5-turbo\"][\"references_sent_to_gpt\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "def replace_placeholder(match, references=references):\n",
    "    index = int(match.group(1))  # Extract the index from the placeholder\n",
    "    return references[index][\"bibref\"]  # Return the corresponding reference\n",
    "\n",
    "# Regular expression pattern to match 'REF{i}'\n",
    "pattern = r'REF(\\d+)'\n",
    "\n",
    "# Replace all occurrences of the pattern in 'candidate'\n",
    "candidate = re.sub(pattern, replace_placeholder, candidate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Discussions and Future Directions - Robustness to Noise\n",
      "\n",
      "Robustness to noise is a crucial aspect of natural language processing (NLP) models, as real-world text data often contains various forms of noise, such as typos, misspellings, and grammatical errors. Transformer-based pretrained models have shown remarkable performance in NLP tasks, but their robustness to noise remains a challenge. In this section, we discuss the impact of noise on transformer-based models and explore potential future directions to improve their robustness.\n",
      "\n",
      "One important aspect to consider is the effect of noise on question answering (QA) systems. In a study by BIBREF290, it was found that even a single typo in the questions can significantly decrease the performance of QA models. This suggests that transformer-based QA systems are more brittle compared to sentiment classifiers based on BERT, as mentioned in BIBREF290. The robustness of NLP systems depends not only on the learning algorithm but also on the specific task.\n",
      "\n",
      "To address the issue of noise, positional embeddings can be utilized. BIBREF68 suggests that preserving the ordering of characters within a block is crucial. By adding positional embeddings to individual blocks, the model can better capture the positional information and distinguish between different blocks. This approach can potentially enhance the robustness of transformer-based models to noise.\n",
      "\n",
      "Another approach to improve robustness is through data augmentation. BIBREF120 proposes changing a percentage of input words in the next sentence prediction (NLM) task and lowering the mask probability in the masked language modeling (MLM) task. This modification aims to avoid excessive information loss in the sequence while introducing noise during pre-training. By training the models on augmented data, they can potentially learn to handle noise more effectively.\n",
      "\n",
      "Furthermore, BIBREF120 suggests that averaging the embeddings from both the character and token channels can enhance the robustness of transformer-based models. By combining the representations from both channels, the model can leverage both character-level and token-level information for better sequence-level classification. This approach can potentially improve the model's ability to handle noise in the input.\n",
      "\n",
      "In addition to these approaches, adversarial attacks can provide insights into the robustness of transformer-based models. BIBREF291 explores adversarially chosen spelling mistakes in the context of text classification. By altering just two characters per sentence, an adversary can degrade the performance of classifiers to random guessing. Understanding the vulnerabilities of transformer-based models to such attacks can guide the development of more robust models.\n",
      "\n",
      "Looking ahead, future research can focus on developing novel architectures or training strategies specifically designed to enhance the robustness of transformer-based models to noise. Additionally, exploring the impact of noise on multilingual models, as discussed in BIBREF67, can provide valuable insights into the generalizability and robustness of these models across different languages.\n",
      "\n",
      "In conclusion, robustness to noise is a critical aspect of transformer-based pretrained models in NLP. The impact of noise on QA systems, the use of positional embeddings, data augmentation, leveraging both character and token information, and understanding adversarial attacks are all important considerations for improving the robustness of these models. Future research should continue to explore these directions to enhance the performance and reliability of transformer-based models in real-world noisy environments.\n",
      "\n",
      "[BIBREF290] \n",
      "[BIBREF68] \n",
      "[BIBREF120] \n",
      "[BIBREF120] \n",
      "[BIBREF291] \n",
      "[BIBREF67]\n"
     ]
    }
   ],
   "source": [
    "print(candidate)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
